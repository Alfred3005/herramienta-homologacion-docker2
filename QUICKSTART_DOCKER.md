# âš¡ GuÃ­a RÃ¡pida - Docker con LLM Local

Puesta en marcha en **5 minutos** del Sistema de HomologaciÃ³n APF v5 con Phi-3.5 Mini local.

---

## ğŸ“‹ Pre-requisitos (VerificaciÃ³n RÃ¡pida)

```bash
# Â¿Tienes Docker?
docker --version
# Esperado: Docker version 20.10+

# Â¿Tienes GPU NVIDIA?
nvidia-smi
# Esperado: Ver informaciÃ³n de tu GPU

# Â¿Tienes NVIDIA Docker?
docker run --rm --gpus all nvidia/cuda:12.0.0-base-ubuntu22.04 nvidia-smi
# Esperado: Ver nvidia-smi dentro del contenedor
```

âŒ **Si alguno falla:** Ver [README_DOCKER.md](./README_DOCKER.md#-instalaciÃ³n) para instalaciÃ³n completa.

---

## ğŸš€ InstalaciÃ³n (3 comandos)

```bash
# 1. Clonar repositorio
git clone https://github.com/Alfred3005/herramienta-homologacion-v5.git
cd herramienta-homologacion-v5

# 2. Configurar variables de entorno
cp .env.docker .env

# 3. Iniciar sistema (descarga automÃ¡tica de Phi-3.5)
docker compose up -d
```

â³ **Primera vez:** Descarga de modelo toma 5-15 minutos (~2.3GB).

---

## ğŸ¯ VerificaciÃ³n

```bash
# Ver progreso de descarga
docker compose logs -f ollama-init

# Verificar que todo estÃ© corriendo
docker compose ps

# DeberÃ­as ver:
# âœ… apf-ollama       (Up, healthy)
# âœ… apf-homologacion (Up, healthy)
```

---

## ğŸŒ Acceder a la AplicaciÃ³n

**URL:** http://localhost:8501

**Â¿No carga?** Espera 1-2 minutos mÃ¡s y refresca el navegador.

---

## ğŸ“Š Monitorear VRAM

```bash
# Ver uso de VRAM una vez
./docker/monitor-vram.sh

# Monitoreo continuo (Ctrl+C para salir)
./docker/monitor-vram.sh --continuous
```

**Esperado:**
- VRAM usada: ~4.5-5GB de 6GB
- Temperatura: <80Â°C
- UtilizaciÃ³n: 0% (en espera), 80-100% (durante anÃ¡lisis)

---

## ğŸ§ª Primer AnÃ¡lisis

1. **Abrir:** http://localhost:8501
2. **Clic en:** "Nuevo AnÃ¡lisis"
3. **Subir:**
   - Excel con puestos (formato SIDEGOR)
   - PDF del reglamento
4. **Configurar filtros** (opcional)
5. **Ejecutar anÃ¡lisis**
6. **Esperar:** ~3 minutos por puesto (26 llamadas LLM)

---

## ğŸ“ Comandos Ãštiles

```bash
# Ver logs en tiempo real
docker compose logs -f

# Reiniciar sistema
docker compose restart

# Detener sistema
docker compose down

# Ver uso de recursos
docker stats

# Diagnosticar problemas
./docker/diagnose.sh
```

---

## â“ Problemas Comunes

### Error: "CUDA out of memory"

```bash
# SoluciÃ³n rÃ¡pida: Usar modelo cuantizado
echo "LLM_MODEL=phi3.5:q4_0" >> .env
docker compose restart
```

### Error: "Could not connect to Ollama"

```bash
# Verificar que Ollama estÃ© corriendo
docker compose ps ollama

# Si no estÃ¡, reiniciar
docker compose restart ollama
```

### Error: "Model not found"

```bash
# Descargar manualmente
docker compose exec ollama ollama pull phi3.5

# Verificar
docker compose exec ollama ollama list
```

---

## ğŸ”§ MÃ¡s Ayuda

- **DocumentaciÃ³n completa:** [README_DOCKER.md](./README_DOCKER.md)
- **Troubleshooting:** [docker/TROUBLESHOOTING.md](./docker/TROUBLESHOOTING.md)
- **AnÃ¡lisis de viabilidad:** [ANALISIS_DOCKERIZACION_LLM_LOCAL.md](./ANALISIS_DOCKERIZACION_LLM_LOCAL.md)

---

## ğŸ“ Comandos de Limpieza (al terminar)

```bash
# Detener y eliminar contenedores (mantiene modelos descargados)
docker compose down

# Eliminar TODO (incluye modelos, requiere re-descarga)
docker compose down -v
```

---

## ğŸ“ˆ Comparativa RÃ¡pida

| Aspecto | Local (Phi-3.5) | API (GPT-4o-mini) |
|---------|-----------------|-------------------|
| **Costo** | $0 | $0.35/puesto |
| **Velocidad** | ~3 min/puesto | ~1 min/puesto |
| **PrecisiÃ³n** | 73% | 86% |
| **Privacidad** | 100% local | Datos en cloud |
| **Setup** | 15 min primera vez | 2 min |

**Â¿CuÃ¡ndo usar local?**
- âœ… Datos sensibles (gobierno)
- âœ… Sin presupuesto para APIs
- âœ… <100 puestos/mes
- âœ… Privacidad es crÃ­tica

**Â¿CuÃ¡ndo usar API?**
- âœ… Necesitas mÃ¡xima precisiÃ³n
- âœ… Urgencia (velocidad crÃ­tica)
- âœ… >500 puestos/mes
- âœ… Sin hardware adecuado

---

## â­ PrÃ³ximos Pasos

1. **Analiza 5-10 puestos de prueba**
2. **Compara resultados con tus expectativas**
3. **Ajusta modelo si es necesario** (ver opciones en README)
4. **Revisa documentaciÃ³n completa** si vas a usar en producciÃ³n

---

**Â¿Listo? Â¡Empieza ahora!**

```bash
docker compose up -d && docker compose logs -f
```

Luego abre: **http://localhost:8501** ğŸš€
