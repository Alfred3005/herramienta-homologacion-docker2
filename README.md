# ðŸ³ Sistema de HomologaciÃ³n APF v5 - EdiciÃ³n Docker Local

Sistema de validaciÃ³n de puestos de la AdministraciÃ³n PÃºblica Federal con **LLM 100% local** (Phi-3.5 Mini) vÃ­a Ollama.

**Costo operativo: $0 MXN** | **Privacidad: 100%** | **Optimizado para 6GB VRAM**

---

## ðŸŽ¯ Â¿QuÃ© es esto?

Esta es la **versiÃ³n dockerizada** del Sistema de HomologaciÃ³n APF v5 que utiliza **modelos de IA locales** en lugar de APIs en la nube. Ideal para:

- âœ… **Privacidad total** - Datos nunca salen del servidor
- âœ… **Costo $0** - Sin gastos de APIs
- âœ… **Sin internet** - Funciona offline una vez instalado
- âœ… **POCs y experimentaciÃ³n** - Perfecto para pruebas de concepto

---

## âš¡ Inicio RÃ¡pido (5 minutos)

> ðŸ“˜ **Â¿Primera vez?** Lee [DEPLOY_COMPLETO.md](./DEPLOY_COMPLETO.md) para instrucciones detalladas paso a paso

### Pre-requisitos

- ðŸ–¥ï¸ **Hardware:** 16GB RAM, 6GB VRAM (GPU NVIDIA)
- ðŸ³ **Software:** Docker + Docker Compose + NVIDIA Docker
- ðŸ§ **OS:** Linux (Ubuntu recomendado) o Windows (Docker Desktop + WSL2)

### InstalaciÃ³n

```bash
# 1. Clonar repositorio
git clone https://github.com/Alfred3005/herramienta-homologacion-docker2.git
cd herramienta-homologacion-docker2

# 2. Configurar
cp .env.docker .env

# 3. Iniciar (descarga automÃ¡tica de Qwen2.5 3B ~1.9GB)
docker compose up -d

# 4. Acceder
# http://localhost:8501
```

**Primera vez:** La descarga del modelo toma 5-10 minutos (Qwen2.5 3B - optimizado para 6GB VRAM).

---

## ðŸ“š DocumentaciÃ³n

- **ðŸš€ [GuÃ­a RÃ¡pida](QUICKSTART_DOCKER.md)** - Empieza aquÃ­ (5 minutos)
- **ðŸ“– [GuÃ­a Completa](README_DOCKER.md)** - DocumentaciÃ³n detallada
- **ðŸ”§ [Troubleshooting](docker/TROUBLESHOOTING.md)** - Soluciones a problemas comunes
- **ðŸ“Š [AnÃ¡lisis TÃ©cnico](ANALISIS_DOCKERIZACION_LLM_LOCAL.md)** - Viabilidad y comparativas

---

## ðŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Host (Linux/WSL2)        â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Streamlit   â”‚  â”‚  Ollama        â”‚  â”‚
â”‚  â”‚  (Web App)   â”‚â—„â”€â”¤  (Qwen2.5 3B) â”‚  â”‚
â”‚  â”‚  :8501       â”‚  â”‚  :11434        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         CPU              GPU (6GB)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**3 contenedores:**
1. `apf-ollama` - Servidor LLM con GPU (Ollama)
2. `apf-homologacion` - AplicaciÃ³n web Streamlit
3. `apf-ollama-init` - Inicializador automÃ¡tico (descarga modelo en primer arranque)

---

## ðŸ“Š Comparativa vs VersiÃ³n API

| Aspecto | API (GPT-4o-mini) | Docker Local (Qwen2.5 3B) |
|---------|-------------------|---------------------------|
| **Costo/puesto** | $0.35 MXN | **$0.00 MXN** |
| **Privacidad** | Datos en cloud | **100% local** |
| **PrecisiÃ³n** | 86% | 75-80% (-6 a -11%) |
| **Velocidad** | ~60s/puesto | ~120-150s/puesto (2-2.5x) |
| **Internet** | Requerido | **Opcional** |
| **VRAM** | N/A | **~3.5GB** |

**Nota:** Sistema optimizado para **6GB VRAM**. Otros modelos disponibles:
- `qwen2.5:7b` (>8GB VRAM, ~80-85% precisiÃ³n)
- `phi3.5` (~4.5GB VRAM, ~70-75% precisiÃ³n)
- `llama3.2:3b` (~3.5GB VRAM, ~73-78% precisiÃ³n)

### ðŸ’° Ahorro Estimado

- **100 puestos/mes:** $420 MXN/aÃ±o
- **1,000 puestos/aÃ±o:** $4,200 MXN/aÃ±o

---

## ðŸŽ“ Casos de Uso Ideales

### âœ… Recomendado para:

- Pruebas de concepto (POC)
- VolÃºmenes bajos (<100 puestos/mes)
- Datos altamente sensibles (gobierno/militar)
- Sin presupuesto para APIs
- Desarrollo y experimentaciÃ³n
- Ambientes sin internet

### âŒ No recomendado para:

- ProducciÃ³n con altos volÃºmenes (>500 puestos/mes)
- Necesidad de mÃ¡xima precisiÃ³n (>85%)
- Tiempo de respuesta crÃ­tico (<1 min/puesto)
- Hardware limitado (<6GB VRAM)

---

## ðŸ› ï¸ Comandos Ãštiles

```bash
# Iniciar sistema
docker compose up -d

# Ver logs
docker compose logs -f

# Monitorear VRAM
./docker/monitor-vram.sh

# Diagnosticar problemas
./docker/diagnose.sh

# Detener sistema
docker compose down

# Limpiar todo (incluye modelos descargados)
docker compose down -v
```

---

## ðŸ”§ Optimizaciones Implementadas

- âœ… **Qwen2.5 3B** (3B parÃ¡metros) con cuantizaciÃ³n Q4 - Optimizado para 6GB VRAM
- âœ… Alternativas disponibles: Phi-3.5, Llama 3.2 3B, Qwen2.5 7B (>8GB)
- âœ… **VRAM optimizada**: ~3.5GB usado de 6GB disponibles (margen seguro)
- âœ… Un solo modelo en memoria (OLLAMA_MAX_LOADED_MODELS=1)
- âœ… Sin procesamiento paralelo (OLLAMA_NUM_PARALLEL=1)
- âœ… Flash Attention activado (reduce VRAM adicional)
- âœ… Timeout extendido para LLM local (120s)
- âœ… Parsing JSON robusto con reparaciÃ³n automÃ¡tica
- âœ… Arquitectura de microservicios (fÃ¡cil escalar)
- âœ… InicializaciÃ³n automÃ¡tica con descarga de modelo
- âœ… **Balance ideal**: PrecisiÃ³n ~75-80% con solo 3.5GB VRAM

---

## ðŸ†˜ Soporte

**Problemas comunes:**
- Ver [docker/TROUBLESHOOTING.md](docker/TROUBLESHOOTING.md)

**Issues de GitHub:**
- https://github.com/Alfred3005/herramienta-homologacion-docker/issues

**VersiÃ³n API (producciÃ³n):**
- https://github.com/Alfred3005/herramienta-homologacion-v5

---

## ðŸ“„ Licencia

MIT License

---

## ðŸ”— Proyectos Relacionados

- **[VersiÃ³n API (v5)](https://github.com/Alfred3005/herramienta-homologacion-v5)** - VersiÃ³n oficial con GPT-4o-mini (mÃ¡xima precisiÃ³n)
- **[VersiÃ³n v4 (legacy)](https://github.com/Alfred3005/HerramientaHomologacionDocker)** - VersiÃ³n anterior

---

## ðŸš€ PrÃ³ximos Pasos

1. Lee [QUICKSTART_DOCKER.md](QUICKSTART_DOCKER.md)
2. Ejecuta `docker compose up -d`
3. Accede a http://localhost:8501
4. Analiza 5-10 puestos de prueba
5. Compara resultados
6. Â¡Contribuye con mejoras!

---

**VersiÃ³n:** 1.0.0
**Fecha:** Noviembre 2025
**Mantenido por:** Sistema de HomologaciÃ³n APF
**Base:** Sistema v5.42 + Ollama + Phi-3.5 Mini
