# ğŸ³ Sistema de HomologaciÃ³n APF v5 - EdiciÃ³n Docker Local

Sistema de validaciÃ³n de puestos de la AdministraciÃ³n PÃºblica Federal con **LLM 100% local** (Phi-3.5 Mini) vÃ­a Ollama.

**Costo operativo: $0 MXN** | **Privacidad: 100%** | **Optimizado para 6GB VRAM**

---

## ğŸ¯ Â¿QuÃ© es esto?

Esta es la **versiÃ³n dockerizada** del Sistema de HomologaciÃ³n APF v5 que utiliza **modelos de IA locales** en lugar de APIs en la nube. Ideal para:

- âœ… **Privacidad total** - Datos nunca salen del servidor
- âœ… **Costo $0** - Sin gastos de APIs
- âœ… **Sin internet** - Funciona offline una vez instalado
- âœ… **POCs y experimentaciÃ³n** - Perfecto para pruebas de concepto

---

## âš¡ Inicio RÃ¡pido (5 minutos)

> ğŸ“˜ **Â¿Primera vez?** Lee [DEPLOY_COMPLETO.md](./DEPLOY_COMPLETO.md) para instrucciones detalladas paso a paso

### Pre-requisitos

- ğŸ–¥ï¸ **Hardware:** 16GB RAM, 6GB VRAM (GPU NVIDIA)
- ğŸ³ **Software:** Docker + Docker Compose + NVIDIA Docker
- ğŸ§ **OS:** Linux (Ubuntu recomendado) o Windows (Docker Desktop + WSL2)

### InstalaciÃ³n

```bash
# 1. Clonar repositorio
git clone https://github.com/Alfred3005/herramienta-homologacion-docker2.git
cd herramienta-homologacion-docker2

# 2. Configurar
cp .env.docker .env

# 3. Iniciar (descarga automÃ¡tica de Qwen2.5 7B ~4.7GB)
docker compose up -d

# 4. Acceder
# http://localhost:8501
```

**Primera vez:** La descarga del modelo toma 10-20 minutos (Qwen2.5 7B - recomendado).

---

## ğŸ“š DocumentaciÃ³n

- **ğŸš€ [GuÃ­a RÃ¡pida](QUICKSTART_DOCKER.md)** - Empieza aquÃ­ (5 minutos)
- **ğŸ“– [GuÃ­a Completa](README_DOCKER.md)** - DocumentaciÃ³n detallada
- **ğŸ”§ [Troubleshooting](docker/TROUBLESHOOTING.md)** - Soluciones a problemas comunes
- **ğŸ“Š [AnÃ¡lisis TÃ©cnico](ANALISIS_DOCKERIZACION_LLM_LOCAL.md)** - Viabilidad y comparativas

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Host (Linux/WSL2)        â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Streamlit   â”‚  â”‚  Ollama        â”‚  â”‚
â”‚  â”‚  (Web App)   â”‚â—„â”€â”¤  (Qwen2.5 7B) â”‚  â”‚
â”‚  â”‚  :8501       â”‚  â”‚  :11434        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         CPU              GPU (6GB)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**3 contenedores:**
1. `apf-ollama` - Servidor LLM con GPU (Ollama)
2. `apf-homologacion` - AplicaciÃ³n web Streamlit
3. `apf-ollama-init` - Inicializador automÃ¡tico (descarga modelo en primer arranque)

---

## ğŸ“Š Comparativa vs VersiÃ³n API

| Aspecto | API (GPT-4o-mini) | Docker Local (Qwen2.5 7B) |
|---------|-------------------|---------------------------|
| **Costo/puesto** | $0.35 MXN | **$0.00 MXN** |
| **Privacidad** | Datos en cloud | **100% local** |
| **PrecisiÃ³n** | 86% | 80-85% (-5 a -10%) |
| **Velocidad** | ~60s/puesto | ~150-180s/puesto (2.5-3x) |
| **Internet** | Requerido | **Opcional** |
| **VRAM** | N/A | ~6GB |

**Nota:** Para hardware con <6GB VRAM, usar `LLM_MODEL=phi3.5` (~4.5GB VRAM, ~73% precisiÃ³n).

### ğŸ’° Ahorro Estimado

- **100 puestos/mes:** $420 MXN/aÃ±o
- **1,000 puestos/aÃ±o:** $4,200 MXN/aÃ±o

---

## ğŸ“ Casos de Uso Ideales

### âœ… Recomendado para:

- Pruebas de concepto (POC)
- VolÃºmenes bajos (<100 puestos/mes)
- Datos altamente sensibles (gobierno/militar)
- Sin presupuesto para APIs
- Desarrollo y experimentaciÃ³n
- Ambientes sin internet

### âŒ No recomendado para:

- ProducciÃ³n con altos volÃºmenes (>500 puestos/mes)
- Necesidad de mÃ¡xima precisiÃ³n (>85%)
- Tiempo de respuesta crÃ­tico (<1 min/puesto)
- Hardware limitado (<6GB VRAM)

---

## ğŸ› ï¸ Comandos Ãštiles

```bash
# Iniciar sistema
docker compose up -d

# Ver logs
docker compose logs -f

# Monitorear VRAM
./docker/monitor-vram.sh

# Diagnosticar problemas
./docker/diagnose.sh

# Detener sistema
docker compose down

# Limpiar todo (incluye modelos descargados)
docker compose down -v
```

---

## ğŸ”§ Optimizaciones Implementadas

- âœ… Qwen2.5 7B (7B parÃ¡metros) con cuantizaciÃ³n Q4 - Mayor precisiÃ³n
- âœ… Phi-3.5 Mini (3.8B parÃ¡metros) disponible como opciÃ³n ligera
- âœ… VRAM optimizada (~6GB con Qwen2.5, ~4.5GB con Phi-3.5)
- âœ… Un solo modelo en memoria (OLLAMA_MAX_LOADED_MODELS=1)
- âœ… Sin procesamiento paralelo (OLLAMA_NUM_PARALLEL=1)
- âœ… Flash Attention activado (reduce VRAM)
- âœ… Timeout extendido para LLM local (120s)
- âœ… Parsing JSON robusto para modelos pequeÃ±os
- âœ… Arquitectura de microservicios (fÃ¡cil escalar)
- âœ… InicializaciÃ³n automÃ¡tica con descarga de modelo

---

## ğŸ†˜ Soporte

**Problemas comunes:**
- Ver [docker/TROUBLESHOOTING.md](docker/TROUBLESHOOTING.md)

**Issues de GitHub:**
- https://github.com/Alfred3005/herramienta-homologacion-docker/issues

**VersiÃ³n API (producciÃ³n):**
- https://github.com/Alfred3005/herramienta-homologacion-v5

---

## ğŸ“„ Licencia

MIT License

---

## ğŸ”— Proyectos Relacionados

- **[VersiÃ³n API (v5)](https://github.com/Alfred3005/herramienta-homologacion-v5)** - VersiÃ³n oficial con GPT-4o-mini (mÃ¡xima precisiÃ³n)
- **[VersiÃ³n v4 (legacy)](https://github.com/Alfred3005/HerramientaHomologacionDocker)** - VersiÃ³n anterior

---

## ğŸš€ PrÃ³ximos Pasos

1. Lee [QUICKSTART_DOCKER.md](QUICKSTART_DOCKER.md)
2. Ejecuta `docker compose up -d`
3. Accede a http://localhost:8501
4. Analiza 5-10 puestos de prueba
5. Compara resultados
6. Â¡Contribuye con mejoras!

---

**VersiÃ³n:** 1.0.0
**Fecha:** Noviembre 2025
**Mantenido por:** Sistema de HomologaciÃ³n APF
**Base:** Sistema v5.42 + Ollama + Phi-3.5 Mini
